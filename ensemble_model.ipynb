{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease prediction based on ensemble machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputï¼š\n",
    "merge_asthma_train.bed merge_asthma_train.bim merge_asthma_train.fam\n",
    "\n",
    "merge_asthma_valid.bed merge_asthma_valid.bim merge_asthma_valid.fam      \n",
    "\n",
    "merge_asthma_test.bed merge_asthma_test.bed merge_asthma_test.bed\n",
    "\n",
    "**â€œasthmaâ€ in the filename is the disease name (variable dis in the code), you can change anyword you like**\n",
    "## output: \n",
    "AUC and prediction score of ensemble model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Calculate SNP associations from training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plink (https://www.cog-genomics.org/plink/1.9/) should be installed first and add the path in ~/.bashrc \n",
    "2. covarfile is the file name with covariats, you can find the format and more information in https://www.cog-genomics.org/plink/1.9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis='asthma'\n",
    "import os\n",
    "cmd=\"plink --adjust --bfile merge_\"+dis+\"_train --covar covarfile --logistic --out \"+dis+\"_train_assoc\"\n",
    "os.system(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate SNP list based on four p-value thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dis='asthma'\n",
    "infile1=open(dis+'_train_assoc.assoc.logistic.adjusted')\n",
    "snplist1=open(dis+'_5E3_SNP','w')\n",
    "snplist2=open(dis+'_5E4_SNP','w')\n",
    "snplist3=open(dis+'_5E5_SNP','w')\n",
    "snplist4=open(dis+'_5E6_SNP','w')\n",
    "SNP1=0\n",
    "SNP2=0\n",
    "SNP3=0\n",
    "SNP4=0\n",
    "linenum=0\n",
    "for line in infile1:\n",
    "    if linenum>0:\n",
    "        A=line.strip('\\n').rsplit()\n",
    "        if float(A[3])<0.005:\n",
    "            snplist1.write(A[1]+'\\n')\n",
    "            SNP1+=1\n",
    "        if float(A[3])<0.0005:\n",
    "            snplist2.write(A[1]+'\\n')\n",
    "            SNP2+=1\n",
    "        if float(A[3])<0.00005:\n",
    "            snplist3.write(A[1]+'\\n')\n",
    "            SNP3+=1\n",
    "        if float(A[3])<0.000005:\n",
    "            snplist4.write(A[1]+'\\n')\n",
    "            SNP4+=1\n",
    "    linenum+=1\n",
    "infile1.close()\n",
    "snplist1.close()\n",
    "snplist2.close()\n",
    "snplist3.close()\n",
    "snplist4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: LD prunning and extract the remaining SNPs from train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis='asthma'\n",
    "for data in ['train','valid','test']:\n",
    "    os.system('plink --bfile merge_'+dis+'_'+data+' --extract '+dis+'_5E3_SNP --make-bed --out '+dis+'_5E3_'+data+'_extract\\n')\n",
    "    os.system('plink --bfile merge_'+dis+'_'+data+' --extract '+dis+'_5E4_SNP --make-bed --out '+dis+'_5E4_'+data+'_extract\\n')\n",
    "    os.system('plink --bfile merge_'+dis+'_'+data+' --extract '+dis+'_5E5_SNP --make-bed --out '+dis+'_5E5_'+data+'_extract\\n')\n",
    "    os.system('plink --bfile merge_'+dis+'_'+data+' --extract '+dis+'_5E6_SNP --make-bed --out '+dis+'_5E6_'+data+'_extract\\n')\n",
    "\n",
    "    os.system('plink --bfile '+dis+'_5E6_train_extract --indep-pairwise 50 5 0.5 --out '+data+'_5E6_'+dis+'\\n')\n",
    "    os.system('plink --bfile '+dis+'_5E5_train_extract --indep-pairwise 50 5 0.5 --out '+data+'_5E5_'+dis+'\\n')\n",
    "    os.system('plink --bfile '+dis+'_5E4_train_extract --indep-pairwise 50 5 0.5 --out '+data+'_5E4_'+dis+'\\n')\n",
    "    os.system('plink --bfile '+dis+'_5E3_train_extract --indep-pairwise 50 5 0.5 --out '+data+'_5E3_'+dis+'\\n')\n",
    "\n",
    "\n",
    "    os.system('plink --bfile '+dis+'_5E6_'+data+'_extract --prune --extract '+data+'_5E6_'+dis+'.prune.in --make-bed --out '+dis+'_'+data+'_5E6_SNP')\n",
    "    os.system('plink --bfile '+dis+'_5E5_'+data+'_extract --prune --extract '+data+'_5E5_'+dis+'.prune.in --make-bed --out '+dis+'_'+data+'_5E5_SNP')\n",
    "    os.system('plink --bfile '+dis+'_5E4_'+data+'_extract --prune --extract '+data+'_5E4_'+dis+'.prune.in --make-bed --out '+dis+'_'+data+'_5E4_SNP')\n",
    "    os.system('plink --bfile '+dis+'_5E3_'+data+'_extract --prune --extract '+data+'_5E3_'+dis+'.prune.in --make-bed --out '+dis+'_'+data+'_5E3_SNP')\n",
    "    \n",
    "    os.system('plink --bfile '+dis+'_'+data+'_5E6_SNP --prune --recodeA --out '+dis+'_'+data+'_5E6_recodeA')\n",
    "    os.system('plink --bfile '+dis+'_'+data+'_5E5_SNP --prune --recodeA --out '+dis+'_'+data+'_5E5_recodeA')\n",
    "    os.system('plink --bfile '+dis+'_'+data+'_5E4_SNP --prune --recodeA --out '+dis+'_'+data+'_5E4_recodeA')\n",
    "    os.system('plink --bfile '+dis+'_'+data+'_5E3_SNP --prune --recodeA --out '+dis+'_'+data+'_5E3_recodeA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Recode genotype and L&E into .npy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice\n",
    "Three files with L&E information (named as **L&E_train.matrix**, **L&E_valid.matrix** and **L&E_test.matrix**) should be prepared. \n",
    "\n",
    "Each row is a L&E and each column is an individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import re\n",
    "import numpy as np\n",
    "import operator\n",
    "from scipy import stats as sta\n",
    "import math\n",
    "import multiprocessing\n",
    "import operator\n",
    "import scipy\n",
    "import os\n",
    "from itertools import groupby\n",
    "from operator import itemgetter \n",
    "def generate_G_P(path_diseaseid,path_data):\n",
    "    phenotype=np.genfromtxt(path_diseaseid,dtype=str) \n",
    "    data=np.genfromtxt(path_data,dtype=str)\n",
    "    SNPindexlist=[]\n",
    "    SNP_id=[]\n",
    "    ind_id=[]\n",
    "    indindexlist=[]\n",
    "    ind_genotype=[]\n",
    "    all_disease=[]\n",
    "    totalind=phenotype.shape[0]\n",
    "    print(totalind)\n",
    "    for i in range(totalind):\n",
    "        print(i)\n",
    "        if i==0:\n",
    "            snpnum=data[0].shape[0]\n",
    "            for j in range(6,snpnum):\n",
    "                SNPindexlist.append(j)\n",
    "                SNP_id.append(data[0][j].split('_')[0])\n",
    "        else:\n",
    "            if len(SNPindexlist)==1:\n",
    "                tmp=data[i][6]\n",
    "                if tmp=='NA':\n",
    "                    tmp='0'\n",
    "            else:\n",
    "                tmp=list(itemgetter(*SNPindexlist)(data[i]))\n",
    "                for x in range(len(tmp)):\n",
    "                    if tmp[x]=='NA':\n",
    "                        tmp[x]='0'\n",
    "            indindexlist.append(i-1)\n",
    "            ind_genotype.append(list(map(int,tmp)))   \n",
    "            ind_id.append(phenotype[i-1][0])\n",
    "            all_disease.append(int(data[i][5])-1)\n",
    "    all_genotype=sta.zscore(ind_genotype)\n",
    "    s=np.isnan(all_genotype)\n",
    "    all_genotype[s]=1\n",
    "    return all_genotype,all_disease,ind_id,SNP_id\n",
    "\n",
    "dis='asthma'\n",
    "os.system('mkdir train')\n",
    "os.system('mkdir valid')\n",
    "os.system('mkdir test')\n",
    "outpath1='./train/'\n",
    "outpath2='./valid/'\n",
    "outpath3='./test/'\n",
    "for i in ['5E3','5E4','5E5','5E6']:\n",
    "    if os.path.exists(dis+'_train_'+i+'_recodeA.raw')==False:\n",
    "        continue\n",
    "    out_train_disease=outpath1+str(dis)+'_disease_train'\n",
    "    out_valid_disease=outpath2+str(dis)+'_disease_valid'\n",
    "    out_test_disease=outpath3+str(dis)+'_disease_test'\n",
    "     \n",
    "    out_geno_train=outpath1+str(dis)+'_genotype_train_'+i\n",
    "    out_geno_valid=outpath2+str(dis)+'_genotype_valid_'+i\n",
    "    out_geno_test=outpath3+str(dis)+'_genotype_test_'+i\n",
    "  \n",
    "    out_snpid=outpath1+str(dis)+'_snpid'\n",
    "\n",
    "    out_train_id=outpath1+str(dis)+'_indid_train'\n",
    "    out_valid_id=outpath2+str(dis)+'_indid_valid'\n",
    "    out_test_id=outpath3+str(dis)+'_indid_test'\n",
    "\n",
    "\n",
    "    [train_genotype,train_disease,train_indid,train_SNPid]=generate_G_P(dis+'_train_'+i+'_SNP.fam',dis+'_train_'+i+'_recodeA.raw')\n",
    "    [valid_genotype,valid_disease,valid_indid,valid_SNPid]=generate_G_P(dis+'_valid_'+i+'_SNP.fam',dis+'_valid_'+i+'_recodeA.raw')\n",
    "    [test_genotype,test_disease,test_indid,test_SNPid]=generate_G_P(dis+'_test_'+i+'_SNP.fam',dis+'_test_'+i+'_recodeA.raw')\n",
    "\n",
    "    np.save(out_snpid,train_SNPid)\n",
    "    np.save(out_geno_train,train_genotype)\n",
    "    np.save(out_geno_valid,valid_genotype)\n",
    "    np.save(out_geno_test,test_genotype)\n",
    "    np.save(out_train_id,train_indid)\n",
    "    np.save(out_valid_id,valid_indid)\n",
    "    np.save(out_test_id,test_indid)\n",
    "    np.save(out_train_disease,train_disease)\n",
    "    np.save(out_valid_disease,valid_disease)\n",
    "    np.save(out_test_disease,test_disease)\n",
    "out_train_pheno=outpath1+str(dis)+'_phenotype_train'\n",
    "out_valid_pheno=outpath2+str(dis)+'_phenotype_valid'\n",
    "out_test_pheno=outpath3+str(dis)+'_phenotype_test'\n",
    "for data in [\"train\",\"valid\",\"test\"]:\n",
    "    self_phenotype=np.genfromtxt('L&E_'+data+'.matrix',dtype=float)\n",
    "    num_L=self_phenotype.shape[0]\n",
    "    for j in range(num_L):\n",
    "        var=np.var(self_phenotype[j])\n",
    "        if var!=0:\n",
    "            all_phenotype.append(sta.zscore(self_phenotype[j]))\n",
    "        else:\n",
    "            all_phenotype.append(self_phenotype[j])\n",
    "    if data=='train':\n",
    "        np.save(out_train_pheno,all_phenotype)\n",
    "    elif data=='valid':\n",
    "        np.save(out_valid_pheno,all_phenotype)\n",
    "    else:\n",
    "        np.save(out_test_pheno,all_phenotype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate 80 candidate models from Neural Network (NN), adaboost (Ada),Gradient Boosting (GB), Lasso Regression (LR), Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ML folder, we will get the prediction scores for the individuals in validation and test sets. Each file includes two column, \n",
    "\n",
    "**Validation set:**\n",
    "\n",
    "*_NN_valid.npy, *_ada_valid.npy, *_GB_valid.npy, *_LR_valid.npy and *_RF_valid.npy \n",
    "\n",
    "**Test set:**\n",
    "\n",
    "*_NN_test.npy, *_ada_test.npy, *_GB_test.npy, *_LR_test.npy and *_RF_test.npy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import operator\n",
    "from scipy import stats as sta\n",
    "import math\n",
    "from scipy.interpolate import spline\n",
    "import operator\n",
    "from itertools import groupby\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from operator import itemgetter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from  sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dir_path1='./train/'\n",
    "dir_path2='./valid/'\n",
    "dir_path3='./test/'\n",
    "os.system('./ML')\n",
    "dis='asthma'\n",
    "\n",
    "disease_train=np.load(dir_path1+dis+'_disease_train.npy')\n",
    "Cxlist_NN=[(20,20,20),(30,30),(10,10,10,10),(30,20,10)]\n",
    "Cxlist_ada=[DecisionTreeClassifier(),LogisticRegression(),ExtraTreeClassifier(),GaussianNB()]\n",
    "Cxlist_GB=[0.0001,0.001,0.01,0.1]\n",
    "Cxlist_LR=[0.0001,0.001,0.01,0.1]\n",
    "Cxlist_RF=[0.0001,0.001,0.01,0.1]\n",
    "for s in [1,2,3,4]:\n",
    "    if s==1:\n",
    "        Geno_train=np.load(dir_path1+dis+'_genotype_train_5E3.npy')\n",
    "        Geno_valid=np.load(dir_path2+dis+'_genotype_valid_5E3.npy')\n",
    "        Geno_test=np.load(dir_path3+dis+'_genotype_test_5E3.npy')\n",
    "    elif s==2:\n",
    "        Geno_train=np.load(dir_path1+dis+'_genotype_train_5E4.npy')\n",
    "        Geno_valid=np.load(dir_path2+dis+'_genotype_valid_5E4.npy')\n",
    "        Geno_test=np.load(dir_path3+dis+'_genotype_test_5E4.npy')\n",
    "    elif s==3:\n",
    "        Geno_train=np.load(dir_path1+dis+'_genotype_train_5E5.npy')\n",
    "        Geno_valid=np.load(dir_path2+dis+'_genotype_valid_5E5.npy')\n",
    "        Geno_test=np.load(dir_path3+dis+'_genotype_test_5E5.npy')\n",
    "    else:\n",
    "        Geno_train=np.load(dir_path1+dis+'_genotype_train_5E6.npy')\n",
    "        Geno_valid=np.load(dir_path2+dis+'_genotype_valid_5E6.npy')\n",
    "        Geno_test=np.load(dir_path3+dis+'_genotype_test_5E6.npy')\n",
    "\n",
    "    for t in [1,2,3,4]:\n",
    "        Cx_NN=Cxlist_NN[t-1]\n",
    "        NN=MLPClassifier(hidden_layer_sizes=Cx_NN,max_iter=1000)\n",
    "        NN.fit(Geno_train,disease_train)\n",
    "        Y=NN.predict_proba(Geno_valid)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_NN_valid.npy',Y[:,1])\n",
    "        Y=NN.predict_proba(Geno_test)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_NN_test.npy',Y[:,1])\n",
    "\n",
    "        Cx_ada=Cxlist_ada[t-1]\n",
    "        ada = AdaBoostClassifier(base_estimator=Cx_ada)\n",
    "        ada.fit(Geno_train,disease_train)\n",
    "        Y=ada.predict_proba(Geno_valid)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_ada_valid.npy',Y[:,1])\n",
    "        Y=ada.predict_proba(Geno_test)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_ada_test.npy',Y[:,1])\n",
    "\n",
    "        Cx_GB=Cxlist_GB[t-1]\n",
    "        GB = GradientBoostingClassifier(min_impurity_decrease=Cx_GB)\n",
    "        GB.fit(Geno_train,disease_train)\n",
    "        Y=GB.predict_proba(Geno_valid)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_GB_valid.npy',Y[:,1])\n",
    "        Y=GB.predict_proba(Geno_test)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_GB_test.npy',Y[:,1])\n",
    "\n",
    "        Cx_LR=Cxlist_LR[t-1]\n",
    "        LR = LogisticRegression(penalty='l1', C=Cx_LR, max_iter=10000)\n",
    "        LR.fit(Geno_train,disease_train)\n",
    "        Y=LR.predict_proba(Geno_valid)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_LR_valid.npy',Y[:,1])\n",
    "        Y=LR.predict_proba(Geno_test)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_LR_test.npy',Y[:,1])\n",
    "\n",
    "        Cx_RF=Cxlist_RF[t-1]\n",
    "        RF = RandomForestClassifier(min_impurity_decrease=Cx_RF)\n",
    "        RF.fit(Geno_train,disease_train)\n",
    "        Y=RF.predict_proba(Geno_valid)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_RF_valid.npy',Y[:,1])\n",
    "        Y=RF.predict_proba(Geno_test)\n",
    "        np.save('./ML/'+dis+'_'+str(s)+'_'+str(t)+'_RF_test.npy',Y[:,1])\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: calculate disease prediction score by ensemble model by integrating 80 models and AUC in the test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step will generate three files as output:\n",
    "\n",
    "***_valid_ensemble.npy**: disease prediction scores by ensemble model for validation set\n",
    "\n",
    "***_valid_ensemble.npy**: disease prediction scores by ensemble model for test set\n",
    "\n",
    "**ensemble**: the value of AUC for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "dir1='./valid/'\n",
    "dir2='./test/'\n",
    "dis='asthma'\n",
    "out=open('ensemble','w')\n",
    "disease_valid=np.load(dir1+dis+'_disease_valid.npy')\n",
    "disease_test=np.load(dir2+dis+'_disease_test.npy')\n",
    "for i in ['GB','NN','ada','RF','LR']:\n",
    "    if i=='GB':\n",
    "        filename1=dis+'_1_1_'+i+'_valid.npy'\n",
    "        filename2=dis+'_1_1_'+i+'_test.npy'\n",
    "        data1=np.load(filename1)\n",
    "        data2=np.load(filename2)\n",
    "        enseinput=data1.reshape(-1,1)\n",
    "        ensetest=data2.reshape(-1,1)\n",
    "    for m in ['1','2','3','4']:\n",
    "        for n in ['1','2','3','4']:\n",
    "            filename1=dis+'_'+m+'_'+n+'_'+i+'_valid.npy'\n",
    "            filename2=dis+'_'+m+'_'+n+'_'+i+'_test.npy'\n",
    "            data1=np.load(filename1)\n",
    "            data2=np.load(filename2)\n",
    "            if i=='GB' and m=='1' and n=='1':\n",
    "                continue\n",
    "            enseinput=np.concatenate((enseinput,data1.reshape(-1,1)),axis=1)\n",
    "            ensetest=np.concatenate((ensetest,data2.reshape(-1,1)),axis=1)\n",
    "LR = LogisticRegression(penalty='l1', max_iter=10000)\n",
    "LR.fit(enseinput,disease_valid)\n",
    "Y1=LR.predict_proba(enseinput)\n",
    "Y2=LR.predict_proba(ensetest)\n",
    "np.save(dis+'_valid_ensemble.npy',Y1[:,1]) \n",
    "np.save(dis+'_test_ensemble.npy',Y2[:,1])\n",
    "AUC_test=roc_auc_score(disease_test,Y2[:,1])\n",
    "out.write(dis+'\\t'+str(AUC_test)+'\\n')\n",
    "out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
